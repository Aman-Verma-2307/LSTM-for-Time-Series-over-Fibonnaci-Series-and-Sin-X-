{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LSTM for  Fibonnaci Series .ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyM171Yffh2HCRztwhMPYtjL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Aman-Verma-2307/LSTM-for-Time-Series-over-Fibonnaci-Series-and-Sin-X-/blob/master/LSTM_for_Fibonnaci_Series_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uy8d-vSqJhCS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### Importing Libraries \n",
        "\n",
        "# Basic Libraries\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "import sys\n",
        "import os"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bg4_kFSEKuoH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "a2a45c8b-6de0-4d6f-d4bc-7ce3d1a5ec43"
      },
      "source": [
        "### Implementing Fibonnaci Series\n",
        "\n",
        "num_terms  = 500\n",
        "\n",
        "for i in range(1,num_terms):\n",
        "  if(i == 1):\n",
        "    X.append(1)\n",
        "  else:\n",
        "    X.append(X[i-1]+X[i-2])\n",
        "\n",
        "print(X,len(X))"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1, 1, 2, 3, 5, 8, 13, 21, 34, 55, 89, 144, 233, 377, 610, 987, 1597, 2584, 4181, 6765, 10946, 17711, 28657, 46368, 75025, 121393, 196418, 317811, 514229, 832040, 1346269, 2178309, 3524578, 5702887, 9227465, 14930352, 24157817, 39088169, 63245986, 102334155, 165580141, 267914296, 433494437, 701408733, 1134903170, 1836311903, 2971215073, 4807526976, 7778742049, 12586269025, 20365011074, 32951280099, 53316291173, 86267571272, 139583862445, 225851433717, 365435296162, 591286729879, 956722026041, 1548008755920, 2504730781961, 4052739537881, 6557470319842, 10610209857723, 17167680177565, 27777890035288, 44945570212853, 72723460248141, 117669030460994, 190392490709135, 308061521170129, 498454011879264, 806515533049393, 1304969544928657, 2111485077978050, 3416454622906707, 5527939700884757, 8944394323791464, 14472334024676221, 23416728348467685, 37889062373143906, 61305790721611591, 99194853094755497, 160500643816367088, 259695496911122585, 420196140727489673, 679891637638612258, 1100087778366101931, 1779979416004714189, 2880067194370816120, 4660046610375530309, 7540113804746346429, 12200160415121876738, 19740274219868223167, 31940434634990099905, 51680708854858323072, 83621143489848422977, 135301852344706746049, 218922995834555169026, 354224848179261915075, 1, 2, 3, 5, 8, 13, 21, 34, 55, 89, 144, 233, 377, 610, 987, 1597, 2584, 4181, 6765, 10946, 17711, 28657, 46368, 75025, 121393, 196418, 317811, 514229, 832040, 1346269, 2178309, 3524578, 5702887, 9227465, 14930352, 24157817, 39088169, 63245986, 102334155, 165580141, 267914296, 433494437, 701408733, 1134903170, 1836311903, 2971215073, 4807526976, 7778742049, 12586269025, 20365011074, 32951280099, 53316291173, 86267571272, 139583862445, 225851433717, 365435296162, 591286729879, 956722026041, 1548008755920, 2504730781961, 4052739537881, 6557470319842, 10610209857723, 17167680177565, 27777890035288, 44945570212853, 72723460248141, 117669030460994, 190392490709135, 308061521170129, 498454011879264, 806515533049393, 1304969544928657, 2111485077978050, 3416454622906707, 5527939700884757, 8944394323791464, 14472334024676221, 23416728348467685, 37889062373143906, 61305790721611591, 99194853094755497, 160500643816367088, 259695496911122585, 420196140727489673, 679891637638612258, 1100087778366101931, 1779979416004714189, 2880067194370816120, 4660046610375530309, 7540113804746346429, 12200160415121876738, 19740274219868223167, 31940434634990099905, 51680708854858323072, 83621143489848422977, 135301852344706746049, 218922995834555169026, 354224848179261915075, 573147844013817084101, 354224848179261915076, 3, 5, 8, 13, 21, 34, 55, 89, 144, 233, 377, 610, 987, 1597, 2584, 4181, 6765, 10946, 17711, 28657, 46368, 75025, 121393, 196418, 317811, 514229, 832040, 1346269, 2178309, 3524578, 5702887, 9227465, 14930352, 24157817, 39088169, 63245986, 102334155, 165580141, 267914296, 433494437, 701408733, 1134903170, 1836311903, 2971215073, 4807526976, 7778742049, 12586269025, 20365011074, 32951280099, 53316291173, 86267571272, 139583862445, 225851433717, 365435296162, 591286729879, 956722026041, 1548008755920, 2504730781961, 4052739537881, 6557470319842, 10610209857723, 17167680177565, 27777890035288, 44945570212853, 72723460248141, 117669030460994, 190392490709135, 308061521170129, 498454011879264, 806515533049393, 1304969544928657, 2111485077978050, 3416454622906707, 5527939700884757, 8944394323791464, 14472334024676221, 23416728348467685, 37889062373143906, 61305790721611591, 99194853094755497, 160500643816367088, 259695496911122585, 420196140727489673, 679891637638612258, 1100087778366101931, 1779979416004714189, 2880067194370816120, 4660046610375530309, 7540113804746346429, 12200160415121876738, 19740274219868223167, 31940434634990099905, 51680708854858323072, 83621143489848422977, 135301852344706746049, 218922995834555169026, 354224848179261915075, 573147844013817084101, 927372692193078999176, 927372692193078999177, 354224848179261915079, 8, 13, 21, 34, 55, 89, 144, 233, 377, 610, 987, 1597, 2584, 4181, 6765, 10946, 17711, 28657, 46368, 75025, 121393, 196418, 317811, 514229, 832040, 1346269, 2178309, 3524578, 5702887, 9227465, 14930352, 24157817, 39088169, 63245986, 102334155, 165580141, 267914296, 433494437, 701408733, 1134903170, 1836311903, 2971215073, 4807526976, 7778742049, 12586269025, 20365011074, 32951280099, 53316291173, 86267571272, 139583862445, 225851433717, 365435296162, 591286729879, 956722026041, 1548008755920, 2504730781961, 4052739537881, 6557470319842, 10610209857723, 17167680177565, 27777890035288, 44945570212853, 72723460248141, 117669030460994, 190392490709135, 308061521170129, 498454011879264, 806515533049393, 1304969544928657, 2111485077978050, 3416454622906707, 5527939700884757, 8944394323791464, 14472334024676221, 23416728348467685, 37889062373143906, 61305790721611591, 99194853094755497, 160500643816367088, 259695496911122585, 420196140727489673, 679891637638612258, 1100087778366101931, 1779979416004714189, 2880067194370816120, 4660046610375530309, 7540113804746346429, 12200160415121876738, 19740274219868223167, 31940434634990099905, 51680708854858323072, 83621143489848422977, 135301852344706746049, 218922995834555169026, 354224848179261915075, 573147844013817084101, 927372692193078999176, 1500520536206896083277, 1854745384386157998353, 1281597540372340914256, 354224848179261915087, 21, 34, 55, 89, 144, 233, 377, 610, 987, 1597, 2584, 4181, 6765, 10946, 17711, 28657, 46368, 75025, 121393, 196418, 317811, 514229, 832040, 1346269, 2178309, 3524578, 5702887, 9227465, 14930352, 24157817, 39088169, 63245986, 102334155, 165580141, 267914296, 433494437, 701408733, 1134903170, 1836311903, 2971215073, 4807526976, 7778742049, 12586269025, 20365011074, 32951280099, 53316291173, 86267571272, 139583862445, 225851433717, 365435296162, 591286729879, 956722026041, 1548008755920, 2504730781961, 4052739537881, 6557470319842, 10610209857723, 17167680177565, 27777890035288, 44945570212853, 72723460248141, 117669030460994, 190392490709135, 308061521170129, 498454011879264, 806515533049393, 1304969544928657, 2111485077978050, 3416454622906707, 5527939700884757, 8944394323791464, 14472334024676221, 23416728348467685, 37889062373143906, 61305790721611591, 99194853094755497, 160500643816367088, 259695496911122585, 420196140727489673, 679891637638612258, 1100087778366101931, 1779979416004714189, 2880067194370816120, 4660046610375530309, 7540113804746346429, 12200160415121876738, 19740274219868223167, 31940434634990099905, 51680708854858323072, 83621143489848422977, 135301852344706746049, 218922995834555169026, 354224848179261915075, 573147844013817084101, 927372692193078999176, 1500520536206896083277, 2427893228399975082453, 3355265920593054081630, 3136342924758498912609, 1635822388551602829343, 354224848179261915108, 55, 89, 144, 233, 377, 610, 987, 1597, 2584, 4181, 6765, 10946, 17711, 28657, 46368, 75025, 121393, 196418, 317811, 514229, 832040, 1346269, 2178309, 3524578, 5702887, 9227465, 14930352, 24157817, 39088169, 63245986, 102334155, 165580141, 267914296, 433494437, 701408733, 1134903170, 1836311903, 2971215073, 4807526976, 7778742049, 12586269025, 20365011074, 32951280099, 53316291173, 86267571272, 139583862445, 225851433717, 365435296162, 591286729879, 956722026041, 1548008755920, 2504730781961, 4052739537881, 6557470319842, 10610209857723, 17167680177565, 27777890035288, 44945570212853, 72723460248141, 117669030460994, 190392490709135, 308061521170129, 498454011879264, 806515533049393, 1304969544928657, 2111485077978050, 3416454622906707, 5527939700884757, 8944394323791464, 14472334024676221, 23416728348467685, 37889062373143906, 61305790721611591, 99194853094755497, 160500643816367088, 259695496911122585, 420196140727489673, 679891637638612258, 1100087778366101931, 1779979416004714189, 2880067194370816120, 4660046610375530309, 7540113804746346429, 12200160415121876738, 19740274219868223167, 31940434634990099905, 51680708854858323072, 83621143489848422977, 135301852344706746049, 218922995834555169026, 354224848179261915075, 573147844013817084101, 927372692193078999176, 1500520536206896083277, 2427893228399975082453] 599\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pp3aDWnVOgv0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "040df9e7-c8d8-40e7-fae3-197963599de1"
      },
      "source": [
        "### Creating Dataset\n",
        "\n",
        "x_ip = np.zeros((len(X)-3,3))\n",
        "y_ip = []\n",
        "\n",
        "for i in range(len(X)-3):\n",
        "  for j in range(3):\n",
        "    x_ip[i,j] = X[i+j]\n",
        "  y_ip.append(X[i+3])\n",
        "y_ip = np.array(y_ip)  \n",
        "  \n",
        "print(x_ip.shape)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(596, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UpyCI5XFQe2L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#### Importing Keras Library\n",
        "\n",
        "from keras import layers\n",
        "from keras import Model\n",
        "import keras.backend as K\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import Dense"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yHFMF8MzQkbQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5827ccbf-5542-4f22-9749-54b04edab99c"
      },
      "source": [
        "### Defining Variables and Reshaping X\n",
        "\n",
        "n_features = 1\n",
        "x_ip = x_ip.reshape((x_ip.shape[0],x_ip.shape[1],n_features))\n",
        "print(x_ip.shape)"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(596, 3, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cfEUe5kFSXpR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### Defining Custom Loss Function\n",
        "\n",
        "def custom_loss(y_ip,y_predicted):\n",
        "  loss = sum(y_ip.shape[0]/(y_ip-y_predicted))\n",
        "  return loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TxqRjX0pQyV4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### Developing the Model\n",
        "\n",
        "model = Sequential()\n",
        "model.add(LSTM(50,input_shape=(x_ip.shape[1],n_features)))\n",
        "model.add(Dense(1))\n",
        "model.compile(optimizer='adam',loss= 'logcosh' ,metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1JlSZpOXQ3k0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "86c9f3f1-ff7d-44b3-b287-3bf3479ebde1"
      },
      "source": [
        "### Fitting Model\n",
        "\n",
        "model.fit(x_ip,y_ip,epochs=200)"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "596/596 [==============================] - 0s 522us/step - loss: 58900771747548061696.0000 - accuracy: 0.0000e+00\n",
            "Epoch 2/200\n",
            "596/596 [==============================] - 0s 84us/step - loss: 58900770308128686080.0000 - accuracy: 0.0000e+00\n",
            "Epoch 3/200\n",
            "596/596 [==============================] - 0s 87us/step - loss: 58900771265128112128.0000 - accuracy: 0.0017\n",
            "Epoch 4/200\n",
            "596/596 [==============================] - 0s 86us/step - loss: 58900772621069467648.0000 - accuracy: 0.0050\n",
            "Epoch 5/200\n",
            "596/596 [==============================] - 0s 86us/step - loss: 58900773552702636032.0000 - accuracy: 0.0017\n",
            "Epoch 6/200\n",
            "596/596 [==============================] - 0s 87us/step - loss: 58900772401536098304.0000 - accuracy: 0.0017\n",
            "Epoch 7/200\n",
            "596/596 [==============================] - 0s 86us/step - loss: 58900773609596542976.0000 - accuracy: 0.0034\n",
            "Epoch 8/200\n",
            "596/596 [==============================] - 0s 85us/step - loss: 58900772792637554688.0000 - accuracy: 0.0017\n",
            "Epoch 9/200\n",
            "596/596 [==============================] - 0s 87us/step - loss: 58900773582219730944.0000 - accuracy: 0.0000e+00\n",
            "Epoch 10/200\n",
            "596/596 [==============================] - 0s 87us/step - loss: 58900773146842644480.0000 - accuracy: 0.0000e+00\n",
            "Epoch 11/200\n",
            "596/596 [==============================] - 0s 87us/step - loss: 58900772401536098304.0000 - accuracy: 0.0000e+00\n",
            "Epoch 12/200\n",
            "596/596 [==============================] - 0s 89us/step - loss: 58900772659868295168.0000 - accuracy: 0.0017\n",
            "Epoch 13/200\n",
            "596/596 [==============================] - 0s 88us/step - loss: 58900771944021196800.0000 - accuracy: 0.0101\n",
            "Epoch 14/200\n",
            "596/596 [==============================] - 0s 88us/step - loss: 58900771878299549696.0000 - accuracy: 0.0084\n",
            "Epoch 15/200\n",
            "596/596 [==============================] - 0s 89us/step - loss: 58900773582219730944.0000 - accuracy: 0.0067\n",
            "Epoch 16/200\n",
            "596/596 [==============================] - 0s 107us/step - loss: 58900773224325005312.0000 - accuracy: 0.0067\n",
            "Epoch 17/200\n",
            "596/596 [==============================] - 0s 95us/step - loss: 58900772434742829056.0000 - accuracy: 0.0050\n",
            "Epoch 18/200\n",
            "596/596 [==============================] - 0s 95us/step - loss: 58900770888785207296.0000 - accuracy: 0.0067\n",
            "Epoch 19/200\n",
            "596/596 [==============================] - 0s 90us/step - loss: 58900773139463372800.0000 - accuracy: 0.0084\n",
            "Epoch 20/200\n",
            "596/596 [==============================] - 0s 90us/step - loss: 58900772084227375104.0000 - accuracy: 0.0117\n",
            "Epoch 21/200\n",
            "596/596 [==============================] - 0s 88us/step - loss: 58900772785258283008.0000 - accuracy: 0.0151\n",
            "Epoch 22/200\n",
            "596/596 [==============================] - 0s 89us/step - loss: 58900772328665792512.0000 - accuracy: 0.0185\n",
            "Epoch 23/200\n",
            "596/596 [==============================] - 0s 90us/step - loss: 58900772785258283008.0000 - accuracy: 0.0151\n",
            "Epoch 24/200\n",
            "596/596 [==============================] - 0s 103us/step - loss: 58900772929154097152.0000 - accuracy: 0.0185\n",
            "Epoch 25/200\n",
            "596/596 [==============================] - 0s 88us/step - loss: 58900773211411275776.0000 - accuracy: 0.0168\n",
            "Epoch 26/200\n",
            "596/596 [==============================] - 0s 90us/step - loss: 58900772969740099584.0000 - accuracy: 0.0151\n",
            "Epoch 27/200\n",
            "596/596 [==============================] - 0s 88us/step - loss: 58900770600993570816.0000 - accuracy: 0.0134\n",
            "Epoch 28/200\n",
            "596/596 [==============================] - 0s 87us/step - loss: 58900771331541565440.0000 - accuracy: 0.0084\n",
            "Epoch 29/200\n",
            "596/596 [==============================] - 0s 87us/step - loss: 58900771250369568768.0000 - accuracy: 0.0201\n",
            "Epoch 30/200\n",
            "596/596 [==============================] - 0s 89us/step - loss: 58900773135773736960.0000 - accuracy: 0.0201\n",
            "Epoch 31/200\n",
            "596/596 [==============================] - 0s 92us/step - loss: 58900773143153008640.0000 - accuracy: 0.0218\n",
            "Epoch 32/200\n",
            "596/596 [==============================] - 0s 108us/step - loss: 58900771544618065920.0000 - accuracy: 0.0185\n",
            "Epoch 33/200\n",
            "596/596 [==============================] - 0s 88us/step - loss: 58900772850749325312.0000 - accuracy: 0.0302\n",
            "Epoch 34/200\n",
            "596/596 [==============================] - 0s 92us/step - loss: 58900771825952833536.0000 - accuracy: 0.0302\n",
            "Epoch 35/200\n",
            "596/596 [==============================] - 0s 86us/step - loss: 58900772622914289664.0000 - accuracy: 0.0218\n",
            "Epoch 36/200\n",
            "596/596 [==============================] - 0s 87us/step - loss: 58900772272398835712.0000 - accuracy: 0.0252\n",
            "Epoch 37/200\n",
            "596/596 [==============================] - 0s 86us/step - loss: 58900773165290831872.0000 - accuracy: 0.0218\n",
            "Epoch 38/200\n",
            "596/596 [==============================] - 0s 89us/step - loss: 58900773287048822784.0000 - accuracy: 0.0218\n",
            "Epoch 39/200\n",
            "596/596 [==============================] - 0s 92us/step - loss: 58900771394265382912.0000 - accuracy: 0.0268\n",
            "Epoch 40/200\n",
            "596/596 [==============================] - 0s 87us/step - loss: 58900773810977185792.0000 - accuracy: 0.0218\n",
            "Epoch 41/200\n",
            "596/596 [==============================] - 0s 88us/step - loss: 58900771320472657920.0000 - accuracy: 0.0235\n",
            "Epoch 42/200\n",
            "596/596 [==============================] - 0s 86us/step - loss: 58900772947602284544.0000 - accuracy: 0.0252\n",
            "Epoch 43/200\n",
            "596/596 [==============================] - 0s 88us/step - loss: 58900774714476879872.0000 - accuracy: 0.0185\n",
            "Epoch 44/200\n",
            "596/596 [==============================] - 0s 85us/step - loss: 58900772438432464896.0000 - accuracy: 0.0185\n",
            "Epoch 45/200\n",
            "596/596 [==============================] - 0s 87us/step - loss: 58900773242773184512.0000 - accuracy: 0.0218\n",
            "Epoch 46/200\n",
            "596/596 [==============================] - 0s 99us/step - loss: 58900771648850296832.0000 - accuracy: 0.0168\n",
            "Epoch 47/200\n",
            "596/596 [==============================] - 0s 87us/step - loss: 58900772327743373312.0000 - accuracy: 0.0168\n",
            "Epoch 48/200\n",
            "596/596 [==============================] - 0s 89us/step - loss: 58900772350803607552.0000 - accuracy: 0.0185\n",
            "Epoch 49/200\n",
            "596/596 [==============================] - 0s 88us/step - loss: 58900771613798744064.0000 - accuracy: 0.0151\n",
            "Epoch 50/200\n",
            "596/596 [==============================] - 0s 88us/step - loss: 58900771309403750400.0000 - accuracy: 0.0386\n",
            "Epoch 51/200\n",
            "596/596 [==============================] - 0s 87us/step - loss: 58900773198497554432.0000 - accuracy: 0.0386\n",
            "Epoch 52/200\n",
            "596/596 [==============================] - 0s 86us/step - loss: 58900772062089560064.0000 - accuracy: 0.0268\n",
            "Epoch 53/200\n",
            "596/596 [==============================] - 0s 96us/step - loss: 58900771722643021824.0000 - accuracy: 0.0336\n",
            "Epoch 54/200\n",
            "596/596 [==============================] - 0s 90us/step - loss: 58900772633983188992.0000 - accuracy: 0.0302\n",
            "Epoch 55/200\n",
            "596/596 [==============================] - 0s 88us/step - loss: 58900773047222460416.0000 - accuracy: 0.0302\n",
            "Epoch 56/200\n",
            "596/596 [==============================] - 0s 87us/step - loss: 58900772279316905984.0000 - accuracy: 0.0403\n",
            "Epoch 57/200\n",
            "596/596 [==============================] - 0s 88us/step - loss: 58900773582219730944.0000 - accuracy: 0.0369\n",
            "Epoch 58/200\n",
            "596/596 [==============================] - 0s 86us/step - loss: 58900772523294105600.0000 - accuracy: 0.0386\n",
            "Epoch 59/200\n",
            "596/596 [==============================] - 0s 88us/step - loss: 58900772062089560064.0000 - accuracy: 0.0403\n",
            "Epoch 60/200\n",
            "596/596 [==============================] - 0s 88us/step - loss: 58900772718844829696.0000 - accuracy: 0.0386\n",
            "Epoch 61/200\n",
            "596/596 [==============================] - 0s 90us/step - loss: 58900772416294649856.0000 - accuracy: 0.0235\n",
            "Epoch 62/200\n",
            "596/596 [==============================] - 0s 88us/step - loss: 58900772540473974784.0000 - accuracy: 0.0268\n",
            "Epoch 63/200\n",
            "596/596 [==============================] - 0s 88us/step - loss: 58900773258454147072.0000 - accuracy: 0.0185\n",
            "Epoch 64/200\n",
            "596/596 [==============================] - 0s 87us/step - loss: 58900773203837435904.0000 - accuracy: 0.0252\n",
            "Epoch 65/200\n",
            "596/596 [==============================] - 0s 91us/step - loss: 58900771884987015168.0000 - accuracy: 0.0268\n",
            "Epoch 66/200\n",
            "596/596 [==============================] - 0s 88us/step - loss: 58900771648850296832.0000 - accuracy: 0.0302\n",
            "Epoch 67/200\n",
            "596/596 [==============================] - 0s 86us/step - loss: 58900772490087374848.0000 - accuracy: 0.0302\n",
            "Epoch 68/200\n",
            "596/596 [==============================] - 0s 88us/step - loss: 58900771781677203456.0000 - accuracy: 0.0336\n",
            "Epoch 69/200\n",
            "596/596 [==============================] - 0s 88us/step - loss: 58900772241267523584.0000 - accuracy: 0.0369\n",
            "Epoch 70/200\n",
            "596/596 [==============================] - 0s 89us/step - loss: 58900772032572473344.0000 - accuracy: 0.0319\n",
            "Epoch 71/200\n",
            "596/596 [==============================] - 0s 88us/step - loss: 58900773790684184576.0000 - accuracy: 0.0319\n",
            "Epoch 72/200\n",
            "596/596 [==============================] - 0s 94us/step - loss: 58900772427215831040.0000 - accuracy: 0.0235\n",
            "Epoch 73/200\n",
            "596/596 [==============================] - 0s 88us/step - loss: 58900772696707014656.0000 - accuracy: 0.0201\n",
            "Epoch 74/200\n",
            "596/596 [==============================] - 0s 88us/step - loss: 58900771951400468480.0000 - accuracy: 0.0285\n",
            "Epoch 75/200\n",
            "596/596 [==============================] - 0s 101us/step - loss: 58900772250261012480.0000 - accuracy: 0.0252\n",
            "Epoch 76/200\n",
            "596/596 [==============================] - 0s 92us/step - loss: 58900772135882285056.0000 - accuracy: 0.0151\n",
            "Epoch 77/200\n",
            "596/596 [==============================] - 0s 87us/step - loss: 58900772037184520192.0000 - accuracy: 0.0218\n",
            "Epoch 78/200\n",
            "596/596 [==============================] - 0s 88us/step - loss: 58900771110163382272.0000 - accuracy: 0.0134\n",
            "Epoch 79/200\n",
            "596/596 [==============================] - 0s 86us/step - loss: 58900771456989208576.0000 - accuracy: 0.0134\n",
            "Epoch 80/200\n",
            "596/596 [==============================] - 0s 87us/step - loss: 58900771966159020032.0000 - accuracy: 0.0034\n",
            "Epoch 81/200\n",
            "596/596 [==============================] - 0s 85us/step - loss: 58900772593397194752.0000 - accuracy: 0.0101\n",
            "Epoch 82/200\n",
            "596/596 [==============================] - 0s 86us/step - loss: 58900774006066700288.0000 - accuracy: 0.0302\n",
            "Epoch 83/200\n",
            "596/596 [==============================] - 0s 87us/step - loss: 58900773327634825216.0000 - accuracy: 0.0268\n",
            "Epoch 84/200\n",
            "596/596 [==============================] - 0s 87us/step - loss: 58900773290738466816.0000 - accuracy: 0.0336\n",
            "Epoch 85/200\n",
            "596/596 [==============================] - 0s 87us/step - loss: 58900771584930226176.0000 - accuracy: 0.0252\n",
            "Epoch 86/200\n",
            "596/596 [==============================] - 0s 87us/step - loss: 58900772512225198080.0000 - accuracy: 0.0403\n",
            "Epoch 87/200\n",
            "596/596 [==============================] - 0s 86us/step - loss: 58900774572887089152.0000 - accuracy: 0.0201\n",
            "Epoch 88/200\n",
            "596/596 [==============================] - 0s 87us/step - loss: 58900771242990288896.0000 - accuracy: 0.0218\n",
            "Epoch 89/200\n",
            "596/596 [==============================] - 0s 89us/step - loss: 58900773818356457472.0000 - accuracy: 0.0302\n",
            "Epoch 90/200\n",
            "596/596 [==============================] - 0s 92us/step - loss: 58900771648850296832.0000 - accuracy: 0.0285\n",
            "Epoch 91/200\n",
            "596/596 [==============================] - 0s 88us/step - loss: 58900771840711385088.0000 - accuracy: 0.0268\n",
            "Epoch 92/200\n",
            "596/596 [==============================] - 0s 87us/step - loss: 58900773163446009856.0000 - accuracy: 0.0285\n",
            "Epoch 93/200\n",
            "596/596 [==============================] - 0s 89us/step - loss: 58900773574840459264.0000 - accuracy: 0.0235\n",
            "Epoch 94/200\n",
            "596/596 [==============================] - 0s 108us/step - loss: 58900772032572473344.0000 - accuracy: 0.0369\n",
            "Epoch 95/200\n",
            "596/596 [==============================] - 0s 91us/step - loss: 58900771669143289856.0000 - accuracy: 0.0369\n",
            "Epoch 96/200\n",
            "596/596 [==============================] - 0s 88us/step - loss: 58900772903326646272.0000 - accuracy: 0.0386\n",
            "Epoch 97/200\n",
            "596/596 [==============================] - 0s 89us/step - loss: 58900774305388453888.0000 - accuracy: 0.0419\n",
            "Epoch 98/200\n",
            "596/596 [==============================] - 0s 89us/step - loss: 58900771930185056256.0000 - accuracy: 0.0285\n",
            "Epoch 99/200\n",
            "596/596 [==============================] - 0s 93us/step - loss: 58900772431053193216.0000 - accuracy: 0.0369\n",
            "Epoch 100/200\n",
            "596/596 [==============================] - 0s 88us/step - loss: 58900772777879011328.0000 - accuracy: 0.0403\n",
            "Epoch 101/200\n",
            "596/596 [==============================] - 0s 88us/step - loss: 58900773065670647808.0000 - accuracy: 0.0419\n",
            "Epoch 102/200\n",
            "596/596 [==============================] - 0s 86us/step - loss: 58900772711465558016.0000 - accuracy: 0.0369\n",
            "Epoch 103/200\n",
            "596/596 [==============================] - 0s 87us/step - loss: 58900772563880108032.0000 - accuracy: 0.0436\n",
            "Epoch 104/200\n",
            "596/596 [==============================] - 0s 89us/step - loss: 58900772372019011584.0000 - accuracy: 0.0336\n",
            "Epoch 105/200\n",
            "596/596 [==============================] - 0s 91us/step - loss: 58900771560299020288.0000 - accuracy: 0.0369\n",
            "Epoch 106/200\n",
            "596/596 [==============================] - 0s 90us/step - loss: 58900772003055378432.0000 - accuracy: 0.0319\n",
            "Epoch 107/200\n",
            "596/596 [==============================] - 0s 88us/step - loss: 58900773985889009664.0000 - accuracy: 0.0201\n",
            "Epoch 108/200\n",
            "596/596 [==============================] - 0s 88us/step - loss: 58900772433820426240.0000 - accuracy: 0.0285\n",
            "Epoch 109/200\n",
            "596/596 [==============================] - 0s 105us/step - loss: 58900773364531191808.0000 - accuracy: 0.0336\n",
            "Epoch 110/200\n",
            "596/596 [==============================] - 0s 87us/step - loss: 58900772308372783104.0000 - accuracy: 0.0436\n",
            "Epoch 111/200\n",
            "596/596 [==============================] - 0s 88us/step - loss: 58900773036153552896.0000 - accuracy: 0.0436\n",
            "Epoch 112/200\n",
            "596/596 [==============================] - 0s 88us/step - loss: 58900772999257194496.0000 - accuracy: 0.0268\n",
            "Epoch 113/200\n",
            "596/596 [==============================] - 0s 88us/step - loss: 58900772132192657408.0000 - accuracy: 0.0268\n",
            "Epoch 114/200\n",
            "596/596 [==============================] - 0s 101us/step - loss: 58900774157802995712.0000 - accuracy: 0.0436\n",
            "Epoch 115/200\n",
            "596/596 [==============================] - 0s 88us/step - loss: 58900772504845926400.0000 - accuracy: 0.0336\n",
            "Epoch 116/200\n",
            "596/596 [==============================] - 0s 89us/step - loss: 58900772966050463744.0000 - accuracy: 0.0352\n",
            "Epoch 117/200\n",
            "596/596 [==============================] - 0s 89us/step - loss: 58900773036153552896.0000 - accuracy: 0.0319\n",
            "Epoch 118/200\n",
            "596/596 [==============================] - 0s 87us/step - loss: 58900772530212175872.0000 - accuracy: 0.0419\n",
            "Epoch 119/200\n",
            "596/596 [==============================] - 0s 86us/step - loss: 58900773194807918592.0000 - accuracy: 0.0369\n",
            "Epoch 120/200\n",
            "596/596 [==============================] - 0s 89us/step - loss: 58900771423782477824.0000 - accuracy: 0.0268\n",
            "Epoch 121/200\n",
            "596/596 [==============================] - 0s 88us/step - loss: 58900772732623314944.0000 - accuracy: 0.0285\n",
            "Epoch 122/200\n",
            "596/596 [==============================] - 0s 93us/step - loss: 58900772376631058432.0000 - accuracy: 0.0302\n",
            "Epoch 123/200\n",
            "596/596 [==============================] - 0s 93us/step - loss: 58900771545540476928.0000 - accuracy: 0.0268\n",
            "Epoch 124/200\n",
            "596/596 [==============================] - 0s 87us/step - loss: 58900772645052104704.0000 - accuracy: 0.0436\n",
            "Epoch 125/200\n",
            "596/596 [==============================] - 0s 88us/step - loss: 58900772076848103424.0000 - accuracy: 0.0369\n",
            "Epoch 126/200\n",
            "596/596 [==============================] - 0s 85us/step - loss: 58900773283359186944.0000 - accuracy: 0.0487\n",
            "Epoch 127/200\n",
            "596/596 [==============================] - 0s 94us/step - loss: 58900772711465558016.0000 - accuracy: 0.0386\n",
            "Epoch 128/200\n",
            "596/596 [==============================] - 0s 86us/step - loss: 58900772565724921856.0000 - accuracy: 0.0201\n",
            "Epoch 129/200\n",
            "596/596 [==============================] - 0s 87us/step - loss: 58900772696707014656.0000 - accuracy: 0.0302\n",
            "Epoch 130/200\n",
            "596/596 [==============================] - 0s 86us/step - loss: 58900773191118282752.0000 - accuracy: 0.0352\n",
            "Epoch 131/200\n",
            "596/596 [==============================] - 0s 84us/step - loss: 58900770952200830976.0000 - accuracy: 0.0386\n",
            "Epoch 132/200\n",
            "596/596 [==============================] - 0s 87us/step - loss: 58900771955090112512.0000 - accuracy: 0.0403\n",
            "Epoch 133/200\n",
            "596/596 [==============================] - 0s 87us/step - loss: 58900772047331016704.0000 - accuracy: 0.0252\n",
            "Epoch 134/200\n",
            "596/596 [==============================] - 0s 86us/step - loss: 58900773493668454400.0000 - accuracy: 0.0336\n",
            "Epoch 135/200\n",
            "596/596 [==============================] - 0s 87us/step - loss: 58900772677336424448.0000 - accuracy: 0.0302\n",
            "Epoch 136/200\n",
            "596/596 [==============================] - 0s 86us/step - loss: 58900771242990288896.0000 - accuracy: 0.0336\n",
            "Epoch 137/200\n",
            "596/596 [==============================] - 0s 85us/step - loss: 58900771937103126528.0000 - accuracy: 0.0285\n",
            "Epoch 138/200\n",
            "596/596 [==============================] - 0s 85us/step - loss: 58900772290847014912.0000 - accuracy: 0.0185\n",
            "Epoch 139/200\n",
            "596/596 [==============================] - 0s 87us/step - loss: 58900772076848103424.0000 - accuracy: 0.0252\n",
            "Epoch 140/200\n",
            "596/596 [==============================] - 0s 88us/step - loss: 58900772213364654080.0000 - accuracy: 0.0235\n",
            "Epoch 141/200\n",
            "596/596 [==============================] - 0s 86us/step - loss: 58900771988296835072.0000 - accuracy: 0.0218\n",
            "Epoch 142/200\n",
            "596/596 [==============================] - 0s 85us/step - loss: 58900773058291367936.0000 - accuracy: 0.0235\n",
            "Epoch 143/200\n",
            "596/596 [==============================] - 0s 85us/step - loss: 58900771252214382592.0000 - accuracy: 0.0319\n",
            "Epoch 144/200\n",
            "596/596 [==============================] - 0s 88us/step - loss: 58900771781677203456.0000 - accuracy: 0.0319\n",
            "Epoch 145/200\n",
            "596/596 [==============================] - 0s 87us/step - loss: 58900772971815518208.0000 - accuracy: 0.0252\n",
            "Epoch 146/200\n",
            "596/596 [==============================] - 0s 99us/step - loss: 58900771634091745280.0000 - accuracy: 0.0218\n",
            "Epoch 147/200\n",
            "596/596 [==============================] - 0s 90us/step - loss: 58900771412713570304.0000 - accuracy: 0.0151\n",
            "Epoch 148/200\n",
            "596/596 [==============================] - 0s 89us/step - loss: 58900771898131341312.0000 - accuracy: 0.0268\n",
            "Epoch 149/200\n",
            "596/596 [==============================] - 0s 86us/step - loss: 58900773126549643264.0000 - accuracy: 0.0436\n",
            "Epoch 150/200\n",
            "596/596 [==============================] - 0s 84us/step - loss: 58900771707884478464.0000 - accuracy: 0.0470\n",
            "Epoch 151/200\n",
            "596/596 [==============================] - 0s 88us/step - loss: 58900771685746655232.0000 - accuracy: 0.0336\n",
            "Epoch 152/200\n",
            "596/596 [==============================] - 0s 87us/step - loss: 58900769656446672896.0000 - accuracy: 0.0352\n",
            "Epoch 153/200\n",
            "596/596 [==============================] - 0s 88us/step - loss: 58900772475328831488.0000 - accuracy: 0.0336\n",
            "Epoch 154/200\n",
            "596/596 [==============================] - 0s 88us/step - loss: 58900773238391742464.0000 - accuracy: 0.0268\n",
            "Epoch 155/200\n",
            "596/596 [==============================] - 0s 87us/step - loss: 58900772858013294592.0000 - accuracy: 0.0319\n",
            "Epoch 156/200\n",
            "596/596 [==============================] - 0s 89us/step - loss: 58900771722643021824.0000 - accuracy: 0.0386\n",
            "Epoch 157/200\n",
            "596/596 [==============================] - 0s 90us/step - loss: 58900771397955018752.0000 - accuracy: 0.0453\n",
            "Epoch 158/200\n",
            "596/596 [==============================] - 0s 86us/step - loss: 58900771272507383808.0000 - accuracy: 0.0336\n",
            "Epoch 159/200\n",
            "596/596 [==============================] - 0s 117us/step - loss: 58900771003163934720.0000 - accuracy: 0.0252\n",
            "Epoch 160/200\n",
            "596/596 [==============================] - 0s 89us/step - loss: 58900772246571376640.0000 - accuracy: 0.0419\n",
            "Epoch 161/200\n",
            "596/596 [==============================] - 0s 87us/step - loss: 58900772953698828288.0000 - accuracy: 0.0436\n",
            "Epoch 162/200\n",
            "596/596 [==============================] - 0s 89us/step - loss: 58900773759322275840.0000 - accuracy: 0.0419\n",
            "Epoch 163/200\n",
            "596/596 [==============================] - 0s 87us/step - loss: 58900772962360827904.0000 - accuracy: 0.0604\n",
            "Epoch 164/200\n",
            "596/596 [==============================] - 0s 94us/step - loss: 58900772372019011584.0000 - accuracy: 0.0537\n",
            "Epoch 165/200\n",
            "596/596 [==============================] - 0s 96us/step - loss: 58900771154439020544.0000 - accuracy: 0.0403\n",
            "Epoch 166/200\n",
            "596/596 [==============================] - 0s 87us/step - loss: 58900772445811736576.0000 - accuracy: 0.0252\n",
            "Epoch 167/200\n",
            "596/596 [==============================] - 0s 86us/step - loss: 58900773093342912512.0000 - accuracy: 0.0319\n",
            "Epoch 168/200\n",
            "596/596 [==============================] - 0s 84us/step - loss: 58900771368437932032.0000 - accuracy: 0.0319\n",
            "Epoch 169/200\n",
            "596/596 [==============================] - 0s 87us/step - loss: 58900772268709191680.0000 - accuracy: 0.0201\n",
            "Epoch 170/200\n",
            "596/596 [==============================] - 0s 86us/step - loss: 58900771855469928448.0000 - accuracy: 0.0336\n",
            "Epoch 171/200\n",
            "596/596 [==============================] - 0s 87us/step - loss: 58900771899745566720.0000 - accuracy: 0.0470\n",
            "Epoch 172/200\n",
            "596/596 [==============================] - 0s 87us/step - loss: 58900773847873552384.0000 - accuracy: 0.0453\n",
            "Epoch 173/200\n",
            "596/596 [==============================] - 0s 87us/step - loss: 58900770246788481024.0000 - accuracy: 0.0352\n",
            "Epoch 174/200\n",
            "596/596 [==============================] - 0s 85us/step - loss: 58900772895947374592.0000 - accuracy: 0.0419\n",
            "Epoch 175/200\n",
            "596/596 [==============================] - 0s 85us/step - loss: 58900772966511673344.0000 - accuracy: 0.0436\n",
            "Epoch 176/200\n",
            "596/596 [==============================] - 0s 86us/step - loss: 58900771833332113408.0000 - accuracy: 0.0487\n",
            "Epoch 177/200\n",
            "596/596 [==============================] - 0s 87us/step - loss: 58900772076848103424.0000 - accuracy: 0.0352\n",
            "Epoch 178/200\n",
            "596/596 [==============================] - 0s 88us/step - loss: 58900771696123756544.0000 - accuracy: 0.0235\n",
            "Epoch 179/200\n",
            "596/596 [==============================] - 0s 86us/step - loss: 58900773504737370112.0000 - accuracy: 0.0319\n",
            "Epoch 180/200\n",
            "596/596 [==============================] - 0s 94us/step - loss: 58900772349881196544.0000 - accuracy: 0.0319\n",
            "Epoch 181/200\n",
            "596/596 [==============================] - 0s 112us/step - loss: 58900772180157923328.0000 - accuracy: 0.0302\n",
            "Epoch 182/200\n",
            "596/596 [==============================] - 0s 111us/step - loss: 58900771693125926912.0000 - accuracy: 0.0201\n",
            "Epoch 183/200\n",
            "596/596 [==============================] - 0s 93us/step - loss: 58900772372019011584.0000 - accuracy: 0.0218\n",
            "Epoch 184/200\n",
            "596/596 [==============================] - 0s 88us/step - loss: 58900773309186637824.0000 - accuracy: 0.0386\n",
            "Epoch 185/200\n",
            "596/596 [==============================] - 0s 88us/step - loss: 58900773316565909504.0000 - accuracy: 0.0352\n",
            "Epoch 186/200\n",
            "596/596 [==============================] - 0s 88us/step - loss: 58900773036153552896.0000 - accuracy: 0.0369\n",
            "Epoch 187/200\n",
            "596/596 [==============================] - 0s 86us/step - loss: 58900771331541565440.0000 - accuracy: 0.0252\n",
            "Epoch 188/200\n",
            "596/596 [==============================] - 0s 89us/step - loss: 58900772711465558016.0000 - accuracy: 0.0218\n",
            "Epoch 189/200\n",
            "596/596 [==============================] - 0s 92us/step - loss: 58900771894211108864.0000 - accuracy: 0.0285\n",
            "Epoch 190/200\n",
            "596/596 [==============================] - 0s 88us/step - loss: 58900773183739002880.0000 - accuracy: 0.0252\n",
            "Epoch 191/200\n",
            "596/596 [==============================] - 0s 85us/step - loss: 58900772383087927296.0000 - accuracy: 0.0218\n",
            "Epoch 192/200\n",
            "596/596 [==============================] - 0s 87us/step - loss: 58900772856283783168.0000 - accuracy: 0.0268\n",
            "Epoch 193/200\n",
            "596/596 [==============================] - 0s 89us/step - loss: 58900771028991385600.0000 - accuracy: 0.0319\n",
            "Epoch 194/200\n",
            "596/596 [==============================] - 0s 87us/step - loss: 58900772165399379968.0000 - accuracy: 0.0302\n",
            "Epoch 195/200\n",
            "596/596 [==============================] - 0s 86us/step - loss: 58900772090914848768.0000 - accuracy: 0.0336\n",
            "Epoch 196/200\n",
            "596/596 [==============================] - 0s 87us/step - loss: 58900771261669081088.0000 - accuracy: 0.0302\n",
            "Epoch 197/200\n",
            "596/596 [==============================] - 0s 87us/step - loss: 58900772091606654976.0000 - accuracy: 0.0319\n",
            "Epoch 198/200\n",
            "596/596 [==============================] - 0s 88us/step - loss: 58900772903326646272.0000 - accuracy: 0.0386\n",
            "Epoch 199/200\n",
            "596/596 [==============================] - 0s 89us/step - loss: 58900772958671192064.0000 - accuracy: 0.0201\n",
            "Epoch 200/200\n",
            "596/596 [==============================] - 0s 87us/step - loss: 58900773774080819200.0000 - accuracy: 0.0201\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.callbacks.History at 0x7f965adb2710>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QlDaB5TpUt2e",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "dbc195c2-a4d9-4866-a718-b6055acd7146"
      },
      "source": [
        "### Predicting Output\n",
        "\n",
        "x_ip = np.array([2,3,5])\n",
        "x_ip = x_ip.reshape((1,3,n_features))\n",
        "y_op = model.predict(x_ip)\n",
        "error = (8-y_op)\n",
        "\n",
        "print(y_op,error)"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[7.778031]] [[0.22196913]]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}